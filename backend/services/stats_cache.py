# backend/services/stats_cache.py
import json
import os
import sys
import pandas as pd
from datetime import datetime

# –ü–æ–ª—É—á–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
CACHE_FILE = os.path.join(PROJECT_ROOT, "backend", "data", "stats_cache.json")
CACHE_DURATION = 360000000  # 1 —á–∞—Å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

def is_cache_valid():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∞–∫—Ç—É–∞–ª–µ–Ω –ª–∏ –∫–µ—à"""
    if not os.path.exists(CACHE_FILE):
        return False
    
    try:
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–µ—à–∞
        cache_time = datetime.fromisoformat(cache_data['timestamp'])
        current_time = datetime.now()
        time_diff = (current_time - cache_time).total_seconds()
        
        return time_diff < CACHE_DURATION
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–µ—à–∞: {e}")
        return False

def load_cached_stats():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –∫–µ—à–∞"""
    if not os.path.exists(CACHE_FILE):
        return None
    
    try:
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)['stats']
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–µ—à–∞: {e}")
        return None

def save_stats_to_cache(stats_data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∫–µ—à"""
    cache_data = {
        'timestamp': datetime.now().isoformat(),
        'stats': stats_data
    }
    
    os.makedirs(os.path.dirname(CACHE_FILE), exist_ok=True)
    
    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(cache_data, f, indent=2, ensure_ascii=False)

def get_cached_stats(csv_path=None, force_refresh=False):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –∫–µ—à–∞ –∏–ª–∏ –≤—ã—á–∏—Å–ª—è–µ—Ç –∑–∞–Ω–æ–≤–æ
    """
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É
    if csv_path is None:
        csv_path = os.path.join(PROJECT_ROOT, "backend", "data", "books_local.csv")
    else:
        csv_path = os.path.join(PROJECT_ROOT, csv_path)
    
    # –ï—Å–ª–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–ª–∏ –∫–µ—à –Ω–µ–≤–∞–ª–∏–¥–µ–Ω - –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º
    if force_refresh or not is_cache_valid():
        print("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
        from backend.services.analysis_service import dataset_stats
        
        fresh_stats = dataset_stats(csv_path, limit=None)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
        save_stats_to_cache(fresh_stats)
        return fresh_stats
    else:
        print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ –∫–µ—à–∞...")
        cached_stats = load_cached_stats()
        if cached_stats:
            return cached_stats
        else:
            # –ï—Å–ª–∏ –∫–µ—à –ø–æ–≤—Ä–µ–∂–¥–µ–Ω, –≤—ã—á–∏—Å–ª—è–µ–º –∑–∞–Ω–æ–≤–æ
            from backend.services.analysis_service import dataset_stats
            fresh_stats = dataset_stats(csv_path, limit=None)
            save_stats_to_cache(fresh_stats)
            return fresh_stats
